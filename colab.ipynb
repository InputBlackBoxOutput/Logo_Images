{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBzva_RmBb13"
      },
      "source": [
        "# Logodix image scraper\n",
        "#### Written by Rutuparn Pawar\n",
        "#### Created on 23 Nov 2021\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edifvgNYB-Ok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2da23ce-9fca-47fe-9ae3-cc77a4a469d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zju2XgmESFm"
      },
      "source": [
        "# Change the path to save in google drive\n",
        "!mkdir \"Logo images\"\n",
        "path = \"Logo images/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDWwSyjR0TUp"
      },
      "source": [
        "# Scrape images from a webpage\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "headers = { 'User-Agent': \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36\"} \n",
        "\n",
        "def logo_scraper(logolist):\n",
        "  for each in logolist:\n",
        "    print(f\"Current logo: {each}\")\n",
        "    url = f\"https://logodix.com/{each}\"\n",
        "    response = requests.request(\"GET\", url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text)\n",
        "    images = soup.find_all(\"img\", src=True)\n",
        "\n",
        "    image_src = [x['src'] for x in images]\n",
        "    image_src = [x for x in image_src if x.endswith('.jpg') or x.endswith('.png') ]\n",
        "\n",
        "    try:\n",
        "      os.mkdir(path + each)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    imcount = 1\n",
        "    for image in tqdm(image_src[1:-27]):\n",
        "        imageFilename = path + f\"{each}/{imcount}.png\"\n",
        "\n",
        "        with open(imageFilename, 'wb') as f:\n",
        "            res = requests.get(\"https://logodix.com/\" + image)\n",
        "            f.write(res.content)\n",
        "        imcount += 1\n",
        "\n",
        "    print(f\"\\t\\t{imcount-1} images scraped\")\n",
        "\n",
        "#------------------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj3Ags75IIhe"
      },
      "source": [
        "# Get all logo images from the website\n",
        "import requests\n",
        "import string\n",
        "\n",
        "for each in string.ascii_lowercase:\n",
        "  url = f\"https://logodix.com/{each}-logos\"\n",
        "\n",
        "  response = requests.request(\"GET\", url, headers=headers)\n",
        "  print(f\"Alphabet: {each} ==> {response}\")\n",
        "  soup = BeautifulSoup(response.text)\n",
        "\n",
        "  titles = soup.find_all(\"img\", title=True)\n",
        "  names = [x['title'] for x in titles]\n",
        "\n",
        "  for i in range(len(names)):\n",
        "    names[i] = names[i][:-5].replace(' ', '-').lower()\n",
        "  \n",
        "  logo_scraper(names)\n",
        "  # print(names)\n",
        "print(\"Done.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ2G2GkgFri0"
      },
      "source": [
        "# Case: URL route != name\n",
        "special = [ \"dunkin-donuts\", \"guns-n-roses\", \"kelloggs\", \"kirkland-ellis\", \"latham-watkins\", \"lays\", \"lowes\", \"macys\", \"mcdonalds\", \"skadden-arps-slate-meagher-flom\", \"sothebys-international-realty\", \"adopt-a-petcom\", \"wendys\"]\n",
        "\n",
        "logo_scraper(special)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HX8xfyV5Tbv"
      },
      "source": [
        "# Print statistics for the scraped images\n",
        "print(f\"Number of brands: {len(os.listdir(path))}\")\n",
        "\n",
        "count = 0\n",
        "for each in os.listdir(path):\n",
        "  if len(os.listdir(path + each)) == 0:\n",
        "    print(each)\n",
        "\n",
        "  count += len(os.listdir(path + each))\n",
        "\n",
        "print(f\"Total image: {count}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4hD3JWPCX05"
      },
      "source": [
        "#EOF"
      ]
    }
  ]
}